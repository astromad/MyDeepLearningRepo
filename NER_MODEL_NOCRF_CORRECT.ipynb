{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER-MODEL-NOCRF-CORRECT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ndqRzJWS0JM75bafPOa-mxWzHwWIXj4S",
      "authorship_tag": "ABX9TyPLISTM3N+3Eslkr2ZGYN7n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/astromad/MyDeepLearningRepo/blob/master/NER_MODEL_NOCRF_CORRECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2Gi8_UgKsQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install sklearn-crfsuite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rOZ2F_fLZaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjUqfKQ7NhkA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow.keras as k\n",
        "import tensorflow as tf\n",
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "#from keras_contrib.layers import CRF\n",
        "# from keras_contrib.losses import crf_loss\n",
        "# from keras_contrib.metrics import crf_accuracy\n",
        "#from tf2CRF import CRF\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from future.utils import iteritems\n",
        "from math import nan\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "from nltk import word_tokenize\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7Jwxk6HNpUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceGetter(object):\n",
        "\n",
        "    def __init__(self, dataset):\n",
        "        self.n_sent = 1\n",
        "        self.dataset = dataset\n",
        "        self.empty = False\n",
        "        def agg_func(s): return [(w, t) for w, t in zip(s[\"word\"].values.tolist(),\n",
        "                                                        s[\"tag\"].values.tolist())]\n",
        "        self.grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "\n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7TSkHDPN6Sc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadData():\n",
        "    # df1 = pd.read_csv(\"/home/radmad/Desktop/OLD-DATA/MY-DeepLearning/KERAS/CUSTOM-NER/ner.csv\",\n",
        "    #              encoding=\"ISO-8859-1\", error_bad_lines=False)\n",
        "    df = pd.read_csv(\"/content/drive/My Drive/ColabData/data_keras.csv\",\n",
        "                 encoding=\"ISO-8859-1\", error_bad_lines=False)\n",
        "    #df2 = None\n",
        "    # frames = [df1,df2]\n",
        "    # df = pd.concat(frames)\n",
        "    # df.head()\n",
        "\n",
        "    data = df[['sentence_idx', 'word', 'tag']]\n",
        "    print(data.head(30))\n",
        "    print('total tags',df['tag'].value_counts())\n",
        "    getter = SentenceGetter(data)\n",
        "    sentences = getter.sentences\n",
        "    print('Printing sentences')\n",
        "    for i in range(3):\n",
        "        print(sentences[i])\n",
        "    words = list(set(data[\"word\"].values))\n",
        "    n_words = len(words)\n",
        "    tags = []\n",
        "    for tag in set(data[\"tag\"].values):\n",
        "        if tag is nan or isinstance(tag, float):\n",
        "            tags.append('unk')\n",
        "        else:\n",
        "            tags.append(tag)\n",
        "    n_tags = len(tags)\n",
        "    print('number of tags=',n_tags)\n",
        "    word2idx = {w: i for i, w in enumerate(words)}\n",
        "    tag2idx = {t: i for i, t in enumerate(tags)}\n",
        "\n",
        "\n",
        "    maxlen = max([len(s) for s in sentences])\n",
        "    random.shuffle(sentences)\n",
        "\n",
        "    X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
        "    X = pad_sequences(maxlen=maxlen, sequences=X, padding=\"post\")\n",
        "    y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
        "    y = pad_sequences(maxlen=maxlen, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
        "    y = [to_categorical(i, num_classes=n_tags) for i in y]\n",
        "\n",
        "    # Split train and test data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    print(X_train.shape)\n",
        "    print(np.array(y_train).shape)\n",
        "    print(\"&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\",len(words))\n",
        "    return (X_train, X_test, y_train, y_test, words, tags, maxlen,word2idx,tag2idx)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvvA6g5ZOLQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history(history):\n",
        "    plt.style.use('ggplot')\n",
        "    accuracy = history.history['accuracy']\n",
        "    val_accuracy = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(accuracy) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, accuracy, 'b', label='Training acc')\n",
        "    plt.plot(x, val_accuracy, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMAIRJZAOY8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_Model(model1,X_test,y_test,word2idx,tag2idx,tags):\n",
        "    idx2tag = {v: k for k, v in iteritems(tag2idx)}\n",
        "    test_pred = model1.predict(X_test, verbose=1)\n",
        "    pred_labels = pred2label(test_pred,idx2tag)\n",
        "    test_labels = pred2label(y_test,idx2tag)\n",
        "    #! pip install seqeval\n",
        "    print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))\n",
        "    #! pip install sklearn_crfsuite\n",
        "    report = flat_classification_report(y_pred=pred_labels, y_true=test_labels)\n",
        "    print(report)\n",
        "\n",
        "    TP = {}\n",
        "    TN = {}\n",
        "    FP = {}\n",
        "    FN = {}\n",
        "    for tag in tag2idx.keys():\n",
        "        TP[tag] = 0\n",
        "        TN[tag] = 0\n",
        "        FP[tag] = 0\n",
        "        FN[tag] = 0\n",
        "\n",
        "    for i, sentence in enumerate(X_test):\n",
        "        y_hat = np.argmax(test_pred[0], axis=-1)\n",
        "        gt = np.argmax(y_test[0], axis=-1)\n",
        "        for idx, (w, pred) in enumerate(zip(sentence, y_hat)):\n",
        "            accumulate_score_by_tag(idx2tag[gt[idx]], tags[pred],TP,TN,FP,FN)\n",
        "\n",
        "    for tag in tag2idx.keys():\n",
        "        print(f'tag:{tag}')\n",
        "        print('\\t TN:{:10}\\tFP:{:10}'.format(TN[tag], FP[tag]))\n",
        "        print('\\t FN:{:10}\\tTP:{:10}'.format(FN[tag], TP[tag]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQRmm1mnOhv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify(str,model,word2idx,words,maxlen,idx2Label):\n",
        "    print('number of words',len(words))\n",
        "    #sentence =word= word_tokenize(str)\n",
        "    #print(sentence)\n",
        "    #X = getSenIndex(sentence,word2idx,words)\n",
        "    X = getSenIndex(str,word2idx,words)\n",
        "    n_words = len(words)\n",
        "    print('number of words',len(words))\n",
        "\n",
        "    word2idx = {w: i for i, w in enumerate(words)}\n",
        "    print(X)\n",
        "    #X = pad_sequences(maxlen=maxlen, sequences=X, padding=\"post\", value=len(words) - 1)\n",
        "    X = pad_sequences(maxlen=maxlen, sequences=X, padding=\"post\")\n",
        "    #X = padding(X,maxlen)\n",
        "    print(np.array(X))\n",
        "    pred = model.predict(np.array(X), verbose=False)[0] \n",
        "    pred = pred.argmax(axis=-1)\n",
        "    pred = [idx2Label[x].strip() for x in pred]\n",
        "    return list(zip(str,pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwLd86piJZvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_Embedding(n_words,n_tags,maxlen,word_embedding_size = 150):\n",
        "    # inputs = Input(shape=(n_words,))\n",
        "    # embedding = Embedding(input_dim=n_words,\n",
        "    #                 output_dim=word_embedding_size, trainable = False, input_length=maxlen)(inputs)\n",
        "    inputs = Input(shape=(maxlen,))\n",
        "    embedding = Embedding(input_dim=n_words+100,\n",
        "                    output_dim=word_embedding_size, trainable = True, input_length=maxlen)(inputs)\n",
        "    return tf.keras.Model(inputs,embedding)\n",
        "\n",
        "def build_RNN(n_words,n_tags,maxlen,word_embedding_size = 150):\n",
        "    #input_emb = Input(shape=(maxlen, word_embedding_size))\n",
        "    input_emb = Input(shape=(maxlen, word_embedding_size))    \n",
        "    \n",
        "    X = Bidirectional(LSTM(units=word_embedding_size, unroll=False, activation='tanh', recurrent_activation='sigmoid',\n",
        "                             use_bias=True, return_sequences=True, dropout=0.5, recurrent_dropout=0.0, kernel_initializer=k.initializers.he_normal()))(input_emb)\n",
        "    X = LSTM(units=word_embedding_size * 2, unroll=False, activation='tanh', recurrent_activation='sigmoid',\n",
        "               use_bias=True, return_sequences=True, dropout=0.5, recurrent_dropout=0.0, kernel_initializer=k.initializers.he_normal())(X)\n",
        "    X = TimeDistributed(Dense(n_tags, activation=\"sigmoid\"))(X)\n",
        "\n",
        "    return tf.keras.Model(input_emb, X)\n",
        "\n",
        "def run_model(model,X_train,y_train):    \n",
        "    # Saving the best model only\n",
        "    # filepath = \"ner-bi-lstm-td-model-{val_accuracy:.2f}.hdf5\"\n",
        "    # checkpoint = ModelCheckpoint(\n",
        "    #     filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "    # callbacks_list = [checkpoint]\n",
        "\n",
        "    # Fit the best model\n",
        "    # history = model.fit(X_train, np.array(y_train), batch_size=256, epochs=20,\n",
        "    #                 validation_split=0.1, verbose=1, callbacks=callbacks_list)\n",
        "    history = model.fit(X_train, np.array(y_train), batch_size=128, epochs=5,\n",
        "                    validation_split=0.1,verbose=1,shuffle=True)\n",
        "    return history\n",
        "\n",
        "\n",
        "\n",
        "# def idx2tag(tag2idx):\n",
        "#     return {v: k for k, v in iteritems(tag2idx)}\n",
        "\n",
        "def pred2label(pred,idx2tag):\n",
        "    \n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            p_i = np.argmax(p)\n",
        "            out_i.append(idx2tag[p_i])\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "\n",
        "def accumulate_score_by_tag(gt,pred,TP,TN,FP,FN):\n",
        "    \"\"\"\n",
        "    For each tag keep stats\n",
        "    \"\"\"\n",
        "    if gt == pred:\n",
        "        TP[gt] += 1\n",
        "    elif gt != 'O' and pred == 'O':\n",
        "        FN[gt] += 1\n",
        "    elif gt == 'O' and pred != 'O':\n",
        "        FP[gt] += 1\n",
        "    else:\n",
        "        TN[gt] += 1\n",
        "\n",
        "\n",
        "def getSenIndex(sen,word2Idx,words):\n",
        "    unknownIdx = len(words)-1\n",
        "    \n",
        "    wordIndices = []    \n",
        "    for word in sen: \n",
        "        #print(word) \n",
        "        #word = str(word)\n",
        "        if word in word2Idx:\n",
        "            wordIdx = word2Idx[word]\n",
        "            #print('word found',word)\n",
        "        elif word.lower() in word2Idx:\n",
        "            wordIdx = word2Idx[word.lower()] \n",
        "            #print('word found',word)                \n",
        "        else:\n",
        "            print('word NOT found, but adding',words.append(word))\n",
        "            print(word)\n",
        "            wordIdx = len(words)\n",
        "           \n",
        "        wordIndices.append(wordIdx) \n",
        "    print(wordIndices)           \n",
        "    return [wordIndices]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UzNeYM5PADV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "tf.random.set_seed(1)\n",
        "os.environ['PYTHONHASHSEED']= '0'\n",
        "# print(X_test[0],X_test[0].shape)\n",
        "# print(X_test[1],X_test[1].shape)\n",
        "# idx2word = {v: k for k, v in iteritems(word2idx)}\n",
        "# word2idx = {w: i for i, w in enumerate(words)}\n",
        "# sentenses = ['my name is  and my ssn is 123-98-1122','my name is  and my ssn is 123-98-1122']\n",
        "# X = [[word2idx[w] for w in s.split()] for s in sentenses]\n",
        "# X = pad_sequences(maxlen=100, sequences=X, padding=\"post\", value=100)\n",
        "# print(X,X.shape)\n",
        "# exit(0)\n",
        "\n",
        "X_train, X_test, y_train, y_test, words, tags, maxlen, word2idx,tag2idx = loadData()\n",
        "print(\"after from data call &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\",len(words))\n",
        "#model= build_Model(len(words),len(tags),maxlen,word_embedding_size = 150)\n",
        "embedding_model = build_Embedding(len(words),len(tags),maxlen,word_embedding_size = 150)\n",
        "RNN_model = build_RNN(len(words),len(tags),maxlen,word_embedding_size = 150)\n",
        "model = tf.keras.Model(embedding_model.input, RNN_model(embedding_model.output))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "history = run_model(model,X_train,y_train)\n",
        "print(\"after running model&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\",len(words))\n",
        "print('Saving Model Weights')\n",
        "RNN_model.save_weights('/content/drive/My Drive/ColabData/NER-MODEL-WEIGHTS')\n",
        "plot_history(history)\n",
        "plt.show()\n",
        "# commenting for now predict_Model(model,X_test,y_test,word2idx,tag2idx,tags)\n",
        "    \n",
        "# tf.keras.models.save_model(\n",
        "#     model, \"/content/drive/My Drive/ColabData/NER-MODEL-WEIGHTS-NOCRF\", overwrite=True, include_optimizer=True, save_format=\"tf\",\n",
        "#     signatures=None, options=None\n",
        "# )\n",
        "\n",
        "# sentences = [idx2word[x] for x in X_test[0]]\n",
        "# print(sentences)\n",
        "# X = [word2idx[s]  for s in sentences]\n",
        "# print(np.array(X))\n",
        "# print(X_test[0])\n",
        "#print('---------------',word2idx.shape[0])\n",
        "#print('---------------',word2idx.shape[1])\n",
        "\n",
        "#     tf.keras.backend.clear_session()\n",
        "#     print(\"-----------------------------------------------\")\n",
        "#     X_train, X_test, y_train, y_test, words, tags, maxlen, word2idx,tag2idx = loadData()\n",
        "#     classifier = k.models.load_model('/home/radmad/Desktop/OLD-DATA/MY-DeepLearning/KERAS/CUSTOM-NER/NER-MODEL-WEIGHTS-NOCRF',compile=False)\n",
        "#     predict_Model(classifier,X_test,y_test,word2idx,tag2idx,tags)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO1zG04rRhfd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1eca1c57-6ab4-4287-dbc4-ca936d9d587d"
      },
      "source": [
        "idx2tag = {v: k for k, v in iteritems(tag2idx)}\n",
        "idx2word = {v: k for k, v in iteritems(word2idx)}\n",
        "print('predicting-----------------------------')\n",
        "test =np.array([X_test[0]])\n",
        "test_pred=model.predict(test)\n",
        "#print(pred2label(test_pred,idx2tag))\n",
        "test_pred = pred2label(test_pred,idx2tag)[0]\n",
        "#print(pred2label(test,idx2word))\n",
        "test_words = [idx2word[x].strip() for x in X_test[0]]\n",
        "print(test_pred)\n",
        "print(test_words)\n",
        "for x,y in zip(test_words,test_pred):\n",
        "        print(x,y)\n",
        "print('Done predicting-----------------------------')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicting-----------------------------\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-NAME', 'I-NAME', 'O', 'O', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'I-SSN', 'O', 'O', 'O', 'O', 'I-CCARD', 'O', 'O', 'O', 'O', 'O', 'O', 'I-PHONE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-NAME', 'I-NAME', 'O', 'O', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'I-SSN', 'O', 'O', 'O', 'O', 'I-CCARD', 'O', 'O', 'O', 'O', 'O', 'O', 'I-PHONE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-NAME', 'I-NAME', 'O', 'O', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'I-SSN', 'O', 'O', 'O', 'I-CCARD', 'O', 'O', 'O', 'O', 'O', 'O', 'I-PHONE', 'O', 'O', 'O', 'O', 'O', 'O', 'I-NAME', 'I-NAME', 'O', 'O', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-CCARD', 'O', 'O', 'O', 'O', 'O', 'O', 'I-PHONE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "['House', 'interest', 'have', 'there.,', 'Her', 'name', 'is', 'Janice', 'Berry', 'Born', 'on', '1990-03-16', ',', 'Her', 'social', 'security', 'number', 'is', '097-13-9852', 'Her', 'card', 'number', 'is', '676203221368', ',', 'and', 'her', 'phone', 'number', 'is', '(901)471-5843x32893', 'Seem', 'may', 'seek', 'fire', 'paper.,', 'Her', 'name', 'is', 'Alexandra', 'Edwards', 'Born', 'on', '1988-08-21', ',', 'Her', 'S', 'S', 'N', 'is', '388-27-7260', 'Her', 'card', 'number', 'is', '180027084371470', ',', 'and', 'her', 'phone', 'number', 'is', '001-430-615-2852x3637', 'Step', 'order', 'now', 'hot', 'various', 'western', 'look', 'fire.,', 'Her', 'name', 'is', 'Thomas', 'Simmons', 'Born', 'on', '2014-02-21', ',', 'Her', 'S', 'S', 'N', 'is', '232 52 7780', 'Her', 'credit', 'is', '30566540963869', ',', 'and', 'her', 'phone', 'number', 'is', '987-277-6275', 'Choice', 'much', 'anyone.,', 'Her', 'name', 'is', 'Kevin', 'Hester', 'Born', 'on', '2007-05-09', ',', 'Her', 'S', 'S', 'N', 'is', '152-06-72', 'Her', 'credit', 'card', 'is', '4038011948448167', ',', 'and', 'her', 'phone', 'number', 'is', '+1-167-272-1441x489', '139-876-0657', '139-876-0657', '139-876-0657', '139-876-0657', '139-876-0657', '139-876-0657', '139-876-0657', '139-876-0657', '139-876-0657', '139-876-0657']\n",
            "House O\n",
            "interest O\n",
            "have O\n",
            "there., O\n",
            "Her O\n",
            "name O\n",
            "is O\n",
            "Janice I-NAME\n",
            "Berry I-NAME\n",
            "Born O\n",
            "on O\n",
            "1990-03-16 I-DATE\n",
            ", O\n",
            "Her O\n",
            "social O\n",
            "security O\n",
            "number O\n",
            "is O\n",
            "097-13-9852 I-SSN\n",
            "Her O\n",
            "card O\n",
            "number O\n",
            "is O\n",
            "676203221368 I-CCARD\n",
            ", O\n",
            "and O\n",
            "her O\n",
            "phone O\n",
            "number O\n",
            "is O\n",
            "(901)471-5843x32893 I-PHONE\n",
            "Seem O\n",
            "may O\n",
            "seek O\n",
            "fire O\n",
            "paper., O\n",
            "Her O\n",
            "name O\n",
            "is O\n",
            "Alexandra I-NAME\n",
            "Edwards I-NAME\n",
            "Born O\n",
            "on O\n",
            "1988-08-21 I-DATE\n",
            ", O\n",
            "Her O\n",
            "S O\n",
            "S O\n",
            "N O\n",
            "is O\n",
            "388-27-7260 I-SSN\n",
            "Her O\n",
            "card O\n",
            "number O\n",
            "is O\n",
            "180027084371470 I-CCARD\n",
            ", O\n",
            "and O\n",
            "her O\n",
            "phone O\n",
            "number O\n",
            "is O\n",
            "001-430-615-2852x3637 I-PHONE\n",
            "Step O\n",
            "order O\n",
            "now O\n",
            "hot O\n",
            "various O\n",
            "western O\n",
            "look O\n",
            "fire., O\n",
            "Her O\n",
            "name O\n",
            "is O\n",
            "Thomas I-NAME\n",
            "Simmons I-NAME\n",
            "Born O\n",
            "on O\n",
            "2014-02-21 I-DATE\n",
            ", O\n",
            "Her O\n",
            "S O\n",
            "S O\n",
            "N O\n",
            "is O\n",
            "232 52 7780 I-SSN\n",
            "Her O\n",
            "credit O\n",
            "is O\n",
            "30566540963869 I-CCARD\n",
            ", O\n",
            "and O\n",
            "her O\n",
            "phone O\n",
            "number O\n",
            "is O\n",
            "987-277-6275 I-PHONE\n",
            "Choice O\n",
            "much O\n",
            "anyone., O\n",
            "Her O\n",
            "name O\n",
            "is O\n",
            "Kevin I-NAME\n",
            "Hester I-NAME\n",
            "Born O\n",
            "on O\n",
            "2007-05-09 I-DATE\n",
            ", O\n",
            "Her O\n",
            "S O\n",
            "S O\n",
            "N O\n",
            "is O\n",
            "152-06-72 O\n",
            "Her O\n",
            "credit O\n",
            "card O\n",
            "is O\n",
            "4038011948448167 I-CCARD\n",
            ", O\n",
            "and O\n",
            "her O\n",
            "phone O\n",
            "number O\n",
            "is O\n",
            "+1-167-272-1441x489 I-PHONE\n",
            "139-876-0657 O\n",
            "139-876-0657 O\n",
            "139-876-0657 O\n",
            "139-876-0657 O\n",
            "139-876-0657 O\n",
            "139-876-0657 O\n",
            "139-876-0657 O\n",
            "139-876-0657 O\n",
            "139-876-0657 O\n",
            "139-876-0657 O\n",
            "Done predicting-----------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HpvASbJRptY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "ebaa5e2f-b593-4bab-bb55-c177ded899fc"
      },
      "source": [
        "print('predicting orbitrary text')\n",
        "str =[idx2word[x] for x in X_test[0]]\n",
        "print('99999999999',str)\n",
        "output =classify(str,model,word2idx,words,maxlen,idx2tag)\n",
        "print(output)\n",
        "# str = 'my name is madhava avvari my ssn is 435-33-0687 and my phone number is 408-306-1500'.split()\n",
        "# print('99999999999',str)\n",
        "# output =classify(str,model,word2idx,words,maxlen,idx2tag)\n",
        "# print(output)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicting orbitrary text\n",
            "99999999999 ['House', 'interest', 'have', 'there.,', 'Her', 'name', 'is', 'Janice', 'Berry', 'Born', 'on', '1990-03-16', ',', 'Her', 'social', 'security', 'number', 'is', '097-13-9852', 'Her', 'card', 'number', 'is', '676203221368', ',', 'and', 'her', 'phone', 'number', 'is', '(901)471-5843x32893', 'Seem', 'may', 'seek', 'fire', 'paper.,', 'Her', 'name', 'is', 'Alexandra', 'Edwards', 'Born', 'on', '1988-08-21', ',', 'Her', 'S', 'S', 'N', 'is', '388-27-7260', 'Her', 'card', 'number', 'is', '180027084371470', ',', 'and', 'her', 'phone', 'number', 'is', '001-430-615-2852x3637', 'Step', 'order', 'now', 'hot', 'various', 'western', 'look', 'fire.,', 'Her', 'name', 'is', 'Thomas', 'Simmons', 'Born', 'on', '2014-02-21', ',', 'Her', 'S', 'S', 'N', 'is', '232 52 7780', 'Her', 'credit', 'is', '30566540963869', ',', 'and', 'her', 'phone', 'number', 'is', '987-277-6275', 'Choice', 'much', 'anyone.,', 'Her', 'name', 'is', 'Kevin', 'Hester', 'Born', 'on', '2007-05-09', ',', 'Her', 'S', 'S', 'N', 'is', '152-06-72', 'Her', 'credit', 'card', 'is', '4038011948448167', ',', 'and', 'her', 'phone', 'number', 'is', '+1-167-272-1441x489', '139-876-0657', '139-876-0657', '139-876-0657', '139-876-0657', '139-876-0657', '139-876-0657', '139-876-0657', '139-876-0657', '139-876-0657', '139-876-0657']\n",
            "number of words 123795\n",
            "[7665, 20096, 56611, 94766, 56927, 20819, 23384, 20102, 35793, 121534, 5815, 94899, 98977, 56927, 55680, 27460, 34866, 23384, 23377, 56927, 39858, 34866, 23384, 4186, 98977, 21260, 112721, 40451, 34866, 23384, 44834, 82956, 117896, 82873, 114113, 18902, 56927, 20819, 23384, 34404, 11477, 121534, 5815, 103628, 98977, 56927, 65388, 65388, 88266, 23384, 10447, 56927, 39858, 34866, 23384, 62288, 98977, 21260, 112721, 40451, 34866, 23384, 81476, 112496, 38652, 39472, 95860, 103396, 60535, 4813, 115830, 56927, 20819, 23384, 43391, 106202, 121534, 5815, 61156, 98977, 56927, 65388, 65388, 88266, 23384, 81711, 56927, 97426, 23384, 32732, 98977, 21260, 112721, 40451, 34866, 23384, 35707, 13197, 119278, 81579, 56927, 20819, 23384, 53212, 44134, 121534, 5815, 82878, 98977, 56927, 65388, 65388, 88266, 23384, 116643, 56927, 97426, 39858, 23384, 98497, 98977, 21260, 112721, 40451, 34866, 23384, 63330, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "number of words 123795\n",
            "[[7665, 20096, 56611, 94766, 56927, 20819, 23384, 20102, 35793, 121534, 5815, 94899, 98977, 56927, 55680, 27460, 34866, 23384, 23377, 56927, 39858, 34866, 23384, 4186, 98977, 21260, 112721, 40451, 34866, 23384, 44834, 82956, 117896, 82873, 114113, 18902, 56927, 20819, 23384, 34404, 11477, 121534, 5815, 103628, 98977, 56927, 65388, 65388, 88266, 23384, 10447, 56927, 39858, 34866, 23384, 62288, 98977, 21260, 112721, 40451, 34866, 23384, 81476, 112496, 38652, 39472, 95860, 103396, 60535, 4813, 115830, 56927, 20819, 23384, 43391, 106202, 121534, 5815, 61156, 98977, 56927, 65388, 65388, 88266, 23384, 81711, 56927, 97426, 23384, 32732, 98977, 21260, 112721, 40451, 34866, 23384, 35707, 13197, 119278, 81579, 56927, 20819, 23384, 53212, 44134, 121534, 5815, 82878, 98977, 56927, 65388, 65388, 88266, 23384, 116643, 56927, 97426, 39858, 23384, 98497, 98977, 21260, 112721, 40451, 34866, 23384, 63330, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[  7665  20096  56611  94766  56927  20819  23384  20102  35793 121534\n",
            "    5815  94899  98977  56927  55680  27460  34866  23384  23377  56927\n",
            "   39858  34866  23384   4186  98977  21260 112721  40451  34866  23384\n",
            "   44834  82956 117896  82873 114113  18902  56927  20819  23384  34404\n",
            "   11477 121534   5815 103628  98977  56927  65388  65388  88266  23384\n",
            "   10447  56927  39858  34866  23384  62288  98977  21260 112721  40451\n",
            "   34866  23384  81476 112496  38652  39472  95860 103396  60535   4813\n",
            "  115830  56927  20819  23384  43391 106202 121534   5815  61156  98977\n",
            "   56927  65388  65388  88266  23384  81711  56927  97426  23384  32732\n",
            "   98977  21260 112721  40451  34866  23384  35707  13197 119278  81579\n",
            "   56927  20819  23384  53212  44134 121534   5815  82878  98977  56927\n",
            "   65388  65388  88266  23384 116643  56927  97426  39858  23384  98497\n",
            "   98977  21260 112721  40451  34866  23384  63330      0      0      0\n",
            "       0      0      0      0      0      0      0]]\n",
            "[('House', 'O'), ('interest', 'O'), ('have', 'O'), ('there.,', 'O'), ('Her', 'O'), ('name', 'O'), ('is', 'O'), ('Janice', 'I-NAME'), ('Berry', 'I-NAME'), ('Born', 'O'), ('on', 'O'), ('1990-03-16', 'I-DATE'), (',', 'O'), ('Her', 'O'), ('social', 'O'), ('security', 'O'), ('number', 'O'), ('is', 'O'), ('097-13-9852', 'I-SSN'), ('Her', 'O'), ('card', 'O'), ('number', 'O'), ('is', 'O'), ('676203221368', 'I-CCARD'), (',', 'O'), ('and', 'O'), ('her', 'O'), ('phone', 'O'), ('number', 'O'), ('is', 'O'), ('(901)471-5843x32893', 'I-PHONE'), ('Seem', 'O'), ('may', 'O'), ('seek', 'O'), ('fire', 'O'), ('paper.,', 'O'), ('Her', 'O'), ('name', 'O'), ('is', 'O'), ('Alexandra', 'I-NAME'), ('Edwards', 'I-NAME'), ('Born', 'O'), ('on', 'O'), ('1988-08-21', 'I-DATE'), (',', 'O'), ('Her', 'O'), ('S', 'O'), ('S', 'O'), ('N', 'O'), ('is', 'O'), ('388-27-7260', 'I-SSN'), ('Her', 'O'), ('card', 'O'), ('number', 'O'), ('is', 'O'), ('180027084371470', 'I-CCARD'), (',', 'O'), ('and', 'O'), ('her', 'O'), ('phone', 'O'), ('number', 'O'), ('is', 'O'), ('001-430-615-2852x3637', 'I-PHONE'), ('Step', 'O'), ('order', 'O'), ('now', 'O'), ('hot', 'O'), ('various', 'O'), ('western', 'O'), ('look', 'O'), ('fire.,', 'O'), ('Her', 'O'), ('name', 'O'), ('is', 'O'), ('Thomas', 'I-NAME'), ('Simmons', 'I-NAME'), ('Born', 'O'), ('on', 'O'), ('2014-02-21', 'I-DATE'), (',', 'O'), ('Her', 'O'), ('S', 'O'), ('S', 'O'), ('N', 'O'), ('is', 'O'), ('232 52 7780', 'I-SSN'), ('Her', 'O'), ('credit', 'O'), ('is', 'O'), ('30566540963869', 'I-CCARD'), (',', 'O'), ('and', 'O'), ('her', 'O'), ('phone', 'O'), ('number', 'O'), ('is', 'O'), ('987-277-6275', 'I-PHONE'), ('Choice', 'O'), ('much', 'O'), ('anyone.,', 'O'), ('Her', 'O'), ('name', 'O'), ('is', 'O'), ('Kevin', 'I-NAME'), ('Hester', 'I-NAME'), ('Born', 'O'), ('on', 'O'), ('2007-05-09', 'I-DATE'), (',', 'O'), ('Her', 'O'), ('S', 'O'), ('S', 'O'), ('N', 'O'), ('is', 'O'), ('152-06-72', 'O'), ('Her', 'O'), ('credit', 'O'), ('card', 'O'), ('is', 'O'), ('4038011948448167', 'I-CCARD'), (',', 'O'), ('and', 'O'), ('her', 'O'), ('phone', 'O'), ('number', 'O'), ('is', 'O'), ('+1-167-272-1441x489', 'I-PHONE'), ('139-876-0657', 'O'), ('139-876-0657', 'O'), ('139-876-0657', 'O'), ('139-876-0657', 'O'), ('139-876-0657', 'O'), ('139-876-0657', 'O'), ('139-876-0657', 'O'), ('139-876-0657', 'O'), ('139-876-0657', 'O'), ('139-876-0657', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}