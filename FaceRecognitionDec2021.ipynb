{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/astromad/MyDeepLearningRepo/blob/master/FaceRecognitionDec2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUpO84KM4IU2"
      },
      "outputs": [],
      "source": [
        "!rm /content/face_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTcHoGiKXDjs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c953d8-77e2-4e40-c2f5-36c0fae21fb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84Z_UVTYXW1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7be10f5e-f1e4-4a1f-c6d1-f21bc0f70bf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dlib in /usr/local/lib/python3.7/dist-packages (19.18.0)\n"
          ]
        }
      ],
      "source": [
        "pip install dlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pp0BrKHFXbZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63917641-1af0-4736-da7e-91abbd5784f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: face_recognition in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (0.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Nd8qcRYg36Q"
      },
      "outputs": [],
      "source": [
        "from imutils import paths #imutils includes opencv functions\n",
        "import face_recognition\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "from PIL import Image,ImageDraw\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def BoundingBox(image,face_locations,name):\n",
        "  pil_image = Image.fromarray(image)\n",
        "  # Now we will extract bounding box points for all detected faces in image\n",
        "  for face_location in face_locations:\n",
        "      # Print the location of each face in this image\n",
        "      top, right, bottom, left = face_location\n",
        "      \n",
        "      # Draw a rectangle using ImageDraw function on image\n",
        "      shape = [(left, top), (right, bottom)] \n",
        "      img1 = ImageDraw.Draw(pil_image)   \n",
        "      \n",
        "      # We set outline color as red and width of 4\n",
        "      img1.rectangle(shape, outline =\"red\", width=4) \n",
        "  # Show final image\n",
        "  pil_image.show()\n",
        "  pil_image.save(name+'.jpg')"
      ],
      "metadata": {
        "id": "5uKmoBiAVbRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagePath = list(paths.list_images('/content/drive/MyDrive/ColabData/FaceData/Training_Data'))\n",
        "known_dict = []\n",
        "name_enc_dict = {}\n",
        "for (i, ip) in enumerate(imagePath):\n",
        "  name = ip.split(os.path.sep)[-2]\n",
        "  img = face_recognition.load_image_file(ip)\n",
        "  # print('Original Dimensions : ',img.shape)\n",
        "  # scale_percent = 90 # percent of original size\n",
        "  # width = int(img.shape[1] * scale_percent / 100)\n",
        "  # height = int(img.shape[0] * scale_percent / 100)\n",
        "  # dim = (width, height)\n",
        "  # resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "  # print('Final Dimensions : ',resized.shape)\n",
        "  rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  boxes = face_recognition.face_locations(img,model='hog')\n",
        "  print(name,boxes,ip)\n",
        "  BoundingBox(img,boxes,name)\n",
        "  \n",
        "  encodings = face_recognition.face_encodings(img, boxes)\n",
        "  for encoding in encodings:\n",
        "      # enc.append(encoding)\n",
        "      # name.append(name)\n",
        "      known_dict.append({name:encodings})\n",
        "print(known_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4-Dkkr203p5",
        "outputId": "4327112f-a3b5-42a6-a655-9c86d9c7b865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Madhava_Avvari [] /content/drive/MyDrive/ColabData/FaceData/Training_Data/Madhava_Avvari/Madhava_Avvari_0001.jpg\n",
            "Harin_Avvari [] /content/drive/MyDrive/ColabData/FaceData/Training_Data/Harin_Avvari/Harin_Avvari_0001.jpg\n",
            "Radha_Kolachala [(1478, 2094, 1940, 1632), (2599, 1644, 2642, 1600)] /content/drive/MyDrive/ColabData/FaceData/Training_Data/Radha_Kolachala/Radha_Kolachala_0001.jpeg\n",
            "Smaran_Avvari [] /content/drive/MyDrive/ColabData/FaceData/Training_Data/Smaran_Avvari/Smaran_Avvari_0001.jpg\n",
            "[{'Radha_Kolachala': [array([-0.03055583,  0.08228377,  0.05761   , -0.11305162, -0.16952913,\n",
            "        0.0603029 , -0.08306392, -0.08950454,  0.27255422, -0.23517084,\n",
            "        0.13835892,  0.07190902, -0.18964685, -0.04474537, -0.03779444,\n",
            "        0.1519092 , -0.13140045, -0.17601073, -0.02822177, -0.09794963,\n",
            "        0.01819291,  0.05806188,  0.02329481,  0.01893965, -0.18492573,\n",
            "       -0.39367267, -0.08649293, -0.0586349 , -0.00446291, -0.078776  ,\n",
            "       -0.05186778,  0.11812532, -0.14972828,  0.00980681,  0.01722537,\n",
            "        0.11911727, -0.03515399, -0.03395062,  0.16553363,  0.06850019,\n",
            "       -0.23665728, -0.0419517 ,  0.07558045,  0.19400263,  0.22163683,\n",
            "        0.04657876,  0.05541347, -0.107321  ,  0.20171148, -0.28482759,\n",
            "        0.04760853,  0.16387352, -0.00161726,  0.0776485 ,  0.1159364 ,\n",
            "       -0.1491567 , -0.00314934,  0.06291185, -0.16394168, -0.01823585,\n",
            "        0.01775564, -0.09577944, -0.09422696, -0.03343859,  0.24894798,\n",
            "        0.1404234 , -0.10281441, -0.14010854,  0.24732557, -0.1943624 ,\n",
            "       -0.07709937,  0.05262364, -0.11026926, -0.14253545, -0.26521057,\n",
            "        0.02853771,  0.39229989,  0.19208518, -0.07400162,  0.08718427,\n",
            "       -0.05843062, -0.01141999,  0.01961776,  0.14006707, -0.06309202,\n",
            "        0.03431323, -0.01715572,  0.06892976,  0.19445109, -0.02286969,\n",
            "        0.01446391,  0.24051943,  0.03068566,  0.11896497,  0.03173947,\n",
            "        0.11000058, -0.15606892, -0.01476179, -0.17321935, -0.03227027,\n",
            "        0.08074268,  0.00362689,  0.03896393,  0.14190172, -0.19265279,\n",
            "        0.18644747, -0.08079106, -0.05708919,  0.00612434, -0.00823951,\n",
            "       -0.04275114, -0.0597494 ,  0.10494579, -0.24280375,  0.14185524,\n",
            "        0.14758419, -0.01265856,  0.20187691,  0.09292328,  0.07594155,\n",
            "        0.01837628, -0.11175655, -0.1522433 , -0.09691137,  0.030531  ,\n",
            "       -0.0569347 , -0.01647822,  0.02004967]), array([-0.06021668,  0.08296829,  0.11843003,  0.04098845, -0.06782586,\n",
            "       -0.03244979, -0.07281798, -0.0891293 ,  0.0481071 , -0.03523999,\n",
            "        0.19398433, -0.05978747, -0.23884231, -0.00712654, -0.0718665 ,\n",
            "        0.15892777, -0.18019195, -0.07634124, -0.08507192, -0.07193349,\n",
            "        0.02449295,  0.10300638,  0.03819437, -0.01855215, -0.06400909,\n",
            "       -0.32892668, -0.0899405 , -0.07602486,  0.02888968, -0.09381549,\n",
            "        0.02783489,  0.11013401, -0.14781541,  0.05360065,  0.03020025,\n",
            "        0.06206037,  0.00527304, -0.09106259,  0.2009576 ,  0.05749873,\n",
            "       -0.16425936, -0.02586767,  0.1090046 ,  0.25148931,  0.21386276,\n",
            "       -0.00158537, -0.03415767, -0.01535117,  0.05452365, -0.27496386,\n",
            "        0.01287163,  0.1701111 ,  0.07224053,  0.13145603,  0.04104904,\n",
            "       -0.16326608,  0.0312764 ,  0.07416669, -0.14668959,  0.03173574,\n",
            "        0.07477421, -0.13726698, -0.02788918, -0.03165878,  0.15484932,\n",
            "        0.11180058, -0.08104149, -0.16050915,  0.10633574, -0.18471892,\n",
            "       -0.07324059,  0.05894101, -0.12236503, -0.12481451, -0.28533959,\n",
            "        0.04965705,  0.34372333,  0.13200168, -0.14750475,  0.00275872,\n",
            "       -0.02274853, -0.03863899,  0.03552444,  0.07651664, -0.07458639,\n",
            "       -0.03758457, -0.10938866,  0.02573477,  0.16464788, -0.03796664,\n",
            "        0.00130537,  0.22487231, -0.04484951,  0.01781645,  0.00828739,\n",
            "        0.02989079, -0.06670199,  0.00088279, -0.11001128, -0.01299478,\n",
            "        0.02539817, -0.10681438,  0.0133365 ,  0.12218596, -0.15792726,\n",
            "        0.0916946 , -0.03632964, -0.04727511,  0.030967  , -0.00133667,\n",
            "       -0.09053537, -0.01545534,  0.18278156, -0.19660963,  0.19155322,\n",
            "        0.18661071,  0.00854274,  0.11146788,  0.07744101,  0.16279405,\n",
            "       -0.05519455, -0.02978959, -0.13455708, -0.0748063 ,  0.0068409 ,\n",
            "        0.00972223, -0.0658831 ,  0.01778935])]}, {'Radha_Kolachala': [array([-0.03055583,  0.08228377,  0.05761   , -0.11305162, -0.16952913,\n",
            "        0.0603029 , -0.08306392, -0.08950454,  0.27255422, -0.23517084,\n",
            "        0.13835892,  0.07190902, -0.18964685, -0.04474537, -0.03779444,\n",
            "        0.1519092 , -0.13140045, -0.17601073, -0.02822177, -0.09794963,\n",
            "        0.01819291,  0.05806188,  0.02329481,  0.01893965, -0.18492573,\n",
            "       -0.39367267, -0.08649293, -0.0586349 , -0.00446291, -0.078776  ,\n",
            "       -0.05186778,  0.11812532, -0.14972828,  0.00980681,  0.01722537,\n",
            "        0.11911727, -0.03515399, -0.03395062,  0.16553363,  0.06850019,\n",
            "       -0.23665728, -0.0419517 ,  0.07558045,  0.19400263,  0.22163683,\n",
            "        0.04657876,  0.05541347, -0.107321  ,  0.20171148, -0.28482759,\n",
            "        0.04760853,  0.16387352, -0.00161726,  0.0776485 ,  0.1159364 ,\n",
            "       -0.1491567 , -0.00314934,  0.06291185, -0.16394168, -0.01823585,\n",
            "        0.01775564, -0.09577944, -0.09422696, -0.03343859,  0.24894798,\n",
            "        0.1404234 , -0.10281441, -0.14010854,  0.24732557, -0.1943624 ,\n",
            "       -0.07709937,  0.05262364, -0.11026926, -0.14253545, -0.26521057,\n",
            "        0.02853771,  0.39229989,  0.19208518, -0.07400162,  0.08718427,\n",
            "       -0.05843062, -0.01141999,  0.01961776,  0.14006707, -0.06309202,\n",
            "        0.03431323, -0.01715572,  0.06892976,  0.19445109, -0.02286969,\n",
            "        0.01446391,  0.24051943,  0.03068566,  0.11896497,  0.03173947,\n",
            "        0.11000058, -0.15606892, -0.01476179, -0.17321935, -0.03227027,\n",
            "        0.08074268,  0.00362689,  0.03896393,  0.14190172, -0.19265279,\n",
            "        0.18644747, -0.08079106, -0.05708919,  0.00612434, -0.00823951,\n",
            "       -0.04275114, -0.0597494 ,  0.10494579, -0.24280375,  0.14185524,\n",
            "        0.14758419, -0.01265856,  0.20187691,  0.09292328,  0.07594155,\n",
            "        0.01837628, -0.11175655, -0.1522433 , -0.09691137,  0.030531  ,\n",
            "       -0.0569347 , -0.01647822,  0.02004967]), array([-0.06021668,  0.08296829,  0.11843003,  0.04098845, -0.06782586,\n",
            "       -0.03244979, -0.07281798, -0.0891293 ,  0.0481071 , -0.03523999,\n",
            "        0.19398433, -0.05978747, -0.23884231, -0.00712654, -0.0718665 ,\n",
            "        0.15892777, -0.18019195, -0.07634124, -0.08507192, -0.07193349,\n",
            "        0.02449295,  0.10300638,  0.03819437, -0.01855215, -0.06400909,\n",
            "       -0.32892668, -0.0899405 , -0.07602486,  0.02888968, -0.09381549,\n",
            "        0.02783489,  0.11013401, -0.14781541,  0.05360065,  0.03020025,\n",
            "        0.06206037,  0.00527304, -0.09106259,  0.2009576 ,  0.05749873,\n",
            "       -0.16425936, -0.02586767,  0.1090046 ,  0.25148931,  0.21386276,\n",
            "       -0.00158537, -0.03415767, -0.01535117,  0.05452365, -0.27496386,\n",
            "        0.01287163,  0.1701111 ,  0.07224053,  0.13145603,  0.04104904,\n",
            "       -0.16326608,  0.0312764 ,  0.07416669, -0.14668959,  0.03173574,\n",
            "        0.07477421, -0.13726698, -0.02788918, -0.03165878,  0.15484932,\n",
            "        0.11180058, -0.08104149, -0.16050915,  0.10633574, -0.18471892,\n",
            "       -0.07324059,  0.05894101, -0.12236503, -0.12481451, -0.28533959,\n",
            "        0.04965705,  0.34372333,  0.13200168, -0.14750475,  0.00275872,\n",
            "       -0.02274853, -0.03863899,  0.03552444,  0.07651664, -0.07458639,\n",
            "       -0.03758457, -0.10938866,  0.02573477,  0.16464788, -0.03796664,\n",
            "        0.00130537,  0.22487231, -0.04484951,  0.01781645,  0.00828739,\n",
            "        0.02989079, -0.06670199,  0.00088279, -0.11001128, -0.01299478,\n",
            "        0.02539817, -0.10681438,  0.0133365 ,  0.12218596, -0.15792726,\n",
            "        0.0916946 , -0.03632964, -0.04727511,  0.030967  , -0.00133667,\n",
            "       -0.09053537, -0.01545534,  0.18278156, -0.19660963,  0.19155322,\n",
            "        0.18661071,  0.00854274,  0.11146788,  0.07744101,  0.16279405,\n",
            "       -0.05519455, -0.02978959, -0.13455708, -0.0748063 ,  0.0068409 ,\n",
            "        0.00972223, -0.0658831 ,  0.01778935])]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0tuYX7a35wyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmJrBgHUiEsP"
      },
      "outputs": [],
      "source": [
        "#get paths of each file in folder named Images\n",
        "#Images here that contains data(folders of various people)\n",
        "imagePath = list(paths.list_images('/content/drive/MyDrive/ColabData/FaceData/Training_Data'))\n",
        "kEncodings = []\n",
        "kNames = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqREO84liZ-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72fb493d-d254-40e0-f99d-39e717bfca6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Dimensions :  (3024, 4032, 3)\n",
            "Original Dimensions :  (2721, 3628, 3)\n",
            "Madhava_Avvari [] /content/drive/MyDrive/ColabData/FaceData/Training_Data/Madhava_Avvari/Madhava_Avvari_0001.jpg\n",
            "Original Dimensions :  (3024, 4032, 3)\n",
            "Original Dimensions :  (2721, 3628, 3)\n",
            "Madhava_Avvari [] /content/drive/MyDrive/ColabData/FaceData/Training_Data/Madhava_Avvari/Madhava_Avvari_0002.jpg\n",
            "Original Dimensions :  (3024, 4032, 3)\n",
            "Original Dimensions :  (2721, 3628, 3)\n",
            "Madhava_Avvari [] /content/drive/MyDrive/ColabData/FaceData/Training_Data/Madhava_Avvari/Madhava_Avvari_0003.jpg\n",
            "Original Dimensions :  (2316, 3088, 3)\n",
            "Original Dimensions :  (2084, 2779, 3)\n",
            "Madhava_Avvari [] /content/drive/MyDrive/ColabData/FaceData/Training_Data/Madhava_Avvari/Madhava_Avvari_0004.jpg\n",
            "Original Dimensions :  (3024, 4032, 3)\n",
            "Original Dimensions :  (2721, 3628, 3)\n",
            "Harin_Avvari [] /content/drive/MyDrive/ColabData/FaceData/Training_Data/Harin_Avvari/Harin_Avvari_0001.jpg\n",
            "Original Dimensions :  (3024, 4032, 3)\n",
            "Original Dimensions :  (2721, 3628, 3)\n",
            "Harin_Avvari [] /content/drive/MyDrive/ColabData/FaceData/Training_Data/Harin_Avvari/Harin_Avvari_0002.jpg\n",
            "Original Dimensions :  (3024, 4032, 3)\n",
            "Original Dimensions :  (2721, 3628, 3)\n",
            "Harin_Avvari [] /content/drive/MyDrive/ColabData/FaceData/Training_Data/Harin_Avvari/Harin_Avvari_0003.jpg\n",
            "Original Dimensions :  (3024, 4032, 3)\n",
            "Original Dimensions :  (2721, 3628, 3)\n",
            "Radha_Kolachala [(1220, 2328, 1774, 1774)] /content/drive/MyDrive/ColabData/FaceData/Training_Data/Radha_Kolachala/Radha_Kolachala_0001.jpeg\n",
            "Original Dimensions :  (3024, 4032, 3)\n",
            "Original Dimensions :  (2721, 3628, 3)\n",
            "Radha_Kolachala [(1324, 1889, 1786, 1426), (2342, 1477, 2378, 1441)] /content/drive/MyDrive/ColabData/FaceData/Training_Data/Radha_Kolachala/Radha_Kolachala_0002.jpeg\n",
            "Original Dimensions :  (3024, 4032, 3)\n",
            "Original Dimensions :  (2721, 3628, 3)\n",
            "Smaran_Avvari [] /content/drive/MyDrive/ColabData/FaceData/Training_Data/Smaran_Avvari/Smaran_Avvari_0001.jpg\n",
            "Original Dimensions :  (3024, 4032, 3)\n",
            "Original Dimensions :  (2721, 3628, 3)\n",
            "Smaran_Avvari [] /content/drive/MyDrive/ColabData/FaceData/Training_Data/Smaran_Avvari/Smaran_Avvari_0002.jpg\n",
            "Original Dimensions :  (3024, 4032, 3)\n",
            "Original Dimensions :  (2721, 3628, 3)\n",
            "Smaran_Avvari [] /content/drive/MyDrive/ColabData/FaceData/Training_Data/Smaran_Avvari/Smaran_Avvari_0003.jpg\n"
          ]
        }
      ],
      "source": [
        "# loop over the image paths\n",
        "for (i, ip) in enumerate(imagePath):\n",
        "  # extract the person name from the image path\n",
        "  name = ip.split(os.path.sep)[-2]\n",
        "  # load the input image and convert it from BGR\n",
        "  #image = cv2.imread(ip)\n",
        "  #rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  img = face_recognition.load_image_file(ip)\n",
        "  print('Original Dimensions : ',img.shape)\n",
        " \n",
        "  scale_percent = 90 # percent of original size\n",
        "  width = int(img.shape[1] * scale_percent / 100)\n",
        "  height = int(img.shape[0] * scale_percent / 100)\n",
        "  dim = (width, height)\n",
        "    \n",
        "  # resize image\n",
        "  resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "  print('Original Dimensions : ',resized.shape)\n",
        "  boxes = face_recognition.face_locations(resized ,model=\"hog\")\n",
        "  print(name,boxes,ip)\n",
        "  # compute the facial embedding for the any face\n",
        "  encodings = face_recognition.face_encodings( resized, boxes)\n",
        "  # loop over the encodings\n",
        "  for encoding in encodings:\n",
        "    if (encoding.all != None):\n",
        "      kEncodings.append(encoding)\n",
        "      kNames.append(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22b66Sy72nMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74835062-dea8-4c51-816a-4b4c1a61716b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Radha_Kolachala', 'Radha_Kolachala', 'Radha_Kolachala', 'Radha_Kolachala', 'Radha_Kolachala', 'Radha_Kolachala', 'Radha_Kolachala', 'Radha_Kolachala', 'Radha_Kolachala', 'Radha_Kolachala', 'Radha_Kolachala', 'Radha_Kolachala']\n"
          ]
        }
      ],
      "source": [
        "print(kNames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpI3yFUOjPFg"
      },
      "outputs": [],
      "source": [
        "\n",
        "#save emcodings along with their names in dictionary data\n",
        "data = {\"encodings\": kEncodings, \"names\": kNames}\n",
        "#use pickle to save data into a file for later use\n",
        "f = open(\"face_enc\", \"wb\")\n",
        "f.write(pickle.dumps(data))#to open file in write mode\n",
        "f.close()#to close file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYerwKnrjmmw"
      },
      "outputs": [],
      "source": [
        "import face_recognition\n",
        "import imutils #imutils includes opencv functions\n",
        "import pickle\n",
        "import time\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEnW5MWrj4BT"
      },
      "outputs": [],
      "source": [
        "#to find path of xml file containing haarCascade file\n",
        "cfp = os.path.dirname(cv2.__file__) + \"/data/haarcascade_frontalface_alt2.xml\"\n",
        "# load the harcaascade in the cascade classifier\n",
        "fc = cv2.CascadeClassifier(cfp)\n",
        "# load the known faces and embeddings saved in last file\n",
        "data = pickle.loads(open('face_enc', \"rb\").read())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lf0absvtt5dr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[\"names\"])"
      ],
      "metadata": {
        "id": "LBv04ZGeLDvk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e250b47-b1cb-484e-f838-b576352507b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Madhava_Avvari', 'Harin_Avvari', 'Radha_Kolachala', 'Radha_Kolachala', 'Radha_Kolachala', 'Smaran_Avvari']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhsxi7Lakfve"
      },
      "outputs": [],
      "source": [
        "#Find path to the image you want to detect face and pass it here\n",
        "# image = cv2.imread(\"/content/drive/MyDrive/ColabData/FaceData/TestPic2.jpeg\")\n",
        "image = cv2.imread(\"/content/drive/MyDrive/ColabData/FaceData/MYMS2493.jpeg\")\n",
        "\n",
        "rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "#convert image to Greyscale for HaarCascade\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "faces = fc.detectMultiScale(gray,\n",
        "scaleFactor=1.1,\n",
        "minNeighbors=6,\n",
        "minSize=(60, 60),\n",
        "flags=cv2.CASCADE_SCALE_IMAGE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUvB4A_Gk69o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786b6ce9-b31f-4023-904d-ef7fbacbd74f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False, False, True, False, False, True]\n",
            "initial Radha_Kolachala\n",
            "initial Smaran_Avvari\n",
            "Smaran_Avvari 1\n",
            "final Smaran_Avvari\n",
            "[True, False, False, False, False, False]\n",
            "initial Madhava_Avvari\n",
            "Madhava_Avvari 1\n",
            "final Madhava_Avvari\n",
            "['Smaran_Avvari', 'Madhava_Avvari']\n"
          ]
        }
      ],
      "source": [
        "# the facial embeddings for face in input\n",
        "encodings = face_recognition.face_encodings(rgb)\n",
        "names = []\n",
        "# loop over the facial embeddings incase\n",
        "# we have multiple embeddings for multiple fcaes\n",
        "for encoding in encodings:\n",
        "  #Compare encodings with encodings in data[\"encodings\"]\n",
        "  #Matches contain array with boolean values True and False\n",
        "  matches = face_recognition.compare_faces(data[\"encodings\"],encoding)\n",
        "  #set name =unknown if no encoding matches\n",
        "  name = \"Unknown\"\n",
        "  print(matches)\n",
        "  # check to see if we have found a match\n",
        "  if True in matches:\n",
        "  #Find positions at which we get True and store them\n",
        "    matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
        "    count = {}\n",
        "    # loop over the matched indexes and maintain a count for\n",
        "    # each recognized face face\n",
        "    for i in matchedIdxs:\n",
        "      #Check the names at respective indexes we stored in matchedIdxs\n",
        "      name = data[\"names\"][i]\n",
        "      print('initial',name)\n",
        "      #increase count for the name we got\n",
        "      count[name] = count.get(name, 0) + 1\n",
        "      #set name which has highest count\n",
        "    print(name,count[name])\n",
        "    #name = max(count, key=count.get)\n",
        "    print('final',name)\n",
        "      # will update the list of names\n",
        "    names.append(name)\n",
        "print(names)  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install face_recognition"
      ],
      "metadata": {
        "id": "_uAYQxywOLVi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "680ba244-d010-4149-8ccf-5cda05a18e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: face_recognition in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (0.3.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import face_recognition\n",
        "import cv2\n",
        "img = cv2.imread('/content/drive/MyDrive/ColabData/FaceData/TestPic.jpeg', cv2.IMREAD_UNCHANGED)\n",
        " \n",
        "print('Original Dimensions : ',img.shape)\n",
        " \n",
        "scale_percent = 80 # percent of original size\n",
        "width = int(img.shape[1] * scale_percent / 100)\n",
        "height = int(img.shape[0] * scale_percent / 100)\n",
        "dim = (width, height)\n",
        "  \n",
        "# resize image\n",
        "resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "print('Original Dimensions : ',resized.shape)\n",
        "image = face_recognition.load_image_file('/content/drive/MyDrive/ColabData/FaceData/Different_people.jpeg')\n",
        "face_locations = face_recognition.face_locations(resized)\n",
        "print(face_locations)\n",
        "for  floc in face_locations:  \n",
        "    top, right, bottom, left = floc \n",
        "    face_image = image[top:bottom, left:right]\n",
        "    pil_image = Image.fromarray(face_image)\n",
        "    pil_image.show()\n",
        "    print(\"I am here\")\n",
        "    #pil_image.save(name.format(top))"
      ],
      "metadata": {
        "id": "FrkJio7-xn7W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa499f1d-d1e5-4727-db71-e1cefa825e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Dimensions :  (2320, 3088, 3)\n",
            "Original Dimensions :  (1856, 2470, 3)\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IuoZmR2OSRgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c3efa53-575c-4f2d-9951-6187a1e6cd05",
        "id": "cD1LNzHeSUdW"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "# the facial embeddings for face in input\n",
        "encodings = face_recognition.face_encodings(resized)\n",
        "names = []\n",
        "# loop over the facial embeddings incase\n",
        "# we have multiple embeddings for multiple fcaes\n",
        "for encoding in encodings:\n",
        "  #Compare encodings with encodings in data[\"encodings\"]\n",
        "  #Matches contain array with boolean values True and False\n",
        "  matches = face_recognition.compare_faces(data[\"encodings\"],encoding)\n",
        "  #set name =unknown if no encoding matches\n",
        "  name = \"Unknown\"\n",
        "  print(matches)\n",
        "  # check to see if we have found a match\n",
        "  if True in matches:\n",
        "  #Find positions at which we get True and store them\n",
        "    matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
        "    count = {}\n",
        "    # loop over the matched indexes and maintain a count for\n",
        "    # each recognized face face\n",
        "    for i in matchedIdxs:\n",
        "      #Check the names at respective indexes we stored in matchedIdxs\n",
        "      name = data[\"names\"][i]\n",
        "      print('initial',name)\n",
        "      #increase count for the name we got\n",
        "      count[name] = count.get(name, 0) + 1\n",
        "      #set name which has highest count\n",
        "    print(name,count[name])\n",
        "    #name = max(count, key=count.get)\n",
        "    print('final',name)\n",
        "      # will update the list of names\n",
        "    names.append(name)\n",
        "print(names)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ratm0HkUl4cn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dda38dd0-77c2-4325-8625-2efdb534d7f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(957, 230, 899, 899) Smaran_Avvari\n",
            "(2168, 876, 648, 648) Madhava_Avvari\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "# do loop over the recognized faces\n",
        "for ((x, y, w, h), name) in zip(faces, names):\n",
        "  print((x, y, w, h), name)\n",
        "  #rescale the face coordinates\n",
        "  # draw the predicted face name on the image\n",
        "  cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "  cv2.putText(image, name, (x, y), cv2.FONT_HERSHEY_SIMPLEX,0.75, (0, 255, 0), 2)\n",
        "#cv2_imshow(image)\n",
        "cv2.imwrite(\"predictedfaces.jpeg\",image)\n",
        "cv2.waitKey(0)\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "FaceRecognitionDec2021.ipynb",
      "provenance": [],
      "mount_file_id": "1_ayBfTUiXD-NxYLKlngUa3yGMG_F78xk",
      "authorship_tag": "ABX9TyNNx2Bz/hNBuO0tlRiHjUC/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}